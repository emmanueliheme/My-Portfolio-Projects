{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.5. Bankruptcy in Taiwan üáπüáº\n",
    "\n",
    "import wqet_grader\n",
    "‚Äã\n",
    "wqet_grader.init(\"Project 5 Assessment\")\n",
    "# Import libraries here\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import wqet_grader\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from IPython.display import VimeoVideo\n",
    "from ipywidgets import interact\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from teaching_tools.widgets import ConfusionMatrixWidget\n",
    "Prepare Data\n",
    "Import\n",
    "Task 5.5.1: Load the contents of the \"data/taiwan-bankruptcy-data.json.gz\" and assign it to the variable taiwan_data.\n",
    "\n",
    "Note that taiwan_data should be a dictionary. You'll create a DataFrame in a later task.\n",
    "\n",
    "# Load data file\n",
    "with gzip.open(\"data/taiwan-bankruptcy-data.json.gz\", \"r\") as f:\n",
    "    taiwan_data = json.load(f)\n",
    "‚Äã\n",
    "print(type(taiwan_data))\n",
    "<class 'dict'>\n",
    "‚Äã\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.1\", taiwan_data[\"metadata\"])\n",
    "Excellent! Keep going.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.2: Extract the key names from taiwan_data and assign them to the variable taiwan_data_keys.\n",
    "\n",
    "Tip: The data in this assignment might be organized differently than the data from the project, so be sure to inspect it first.\n",
    "taiwan_data_keys = taiwan_data.keys()\n",
    "print(taiwan_data_keys)\n",
    "dict_keys(['schema', 'metadata', 'observations'])\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.2\", list(taiwan_data_keys))\n",
    "Excellent! Keep going.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.3: Calculate how many companies are in taiwan_data and assign the result to n_companies.\n",
    "\n",
    "n_companies = len(taiwan_data[\"observations\"])\n",
    "print(n_companies)\n",
    "‚Äã\n",
    "6137\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.3\", [n_companies])\n",
    "Boom! You got it.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.4: Calculate the number of features associated with each company and assign the result to n_features.\n",
    "\n",
    "n_features = len(taiwan_data[\"observations\"][0])\n",
    "print(n_features)\n",
    "97\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.4\", [n_features])\n",
    "Yup. You got it.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.5: Create a wrangle function that takes as input the path of a compressed JSON file and returns the file's contents as a DataFrame. Be sure that the index of the DataFrame contains the ID of the companies. When your function is complete, use it to load the data into the DataFrame df.\n",
    "\n",
    "taiwan_data[\"observations\"][0]\n",
    "# Create wrangle function\n",
    "def wrangle(filename):\n",
    "    with gzip.open(filename, \"r\") as f:\n",
    "        taiwan_data = json.load(f)\n",
    "        \n",
    "    df = pd.DataFrame().from_dict(taiwan_data[\"observations\"]).set_index(\"id\")\n",
    "    \n",
    "    return df\n",
    "‚Äã\n",
    "df = pd.DataFrame().from_dict(taiwan_data[\"observations\"]).set_index(\"id\")\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()\n",
    "df shape: (6137, 96)\n",
    "bankrupt\tfeat_1\tfeat_2\tfeat_3\tfeat_4\tfeat_5\tfeat_6\tfeat_7\tfeat_8\tfeat_9\t...\tfeat_86\tfeat_87\tfeat_88\tfeat_89\tfeat_90\tfeat_91\tfeat_92\tfeat_93\tfeat_94\tfeat_95\n",
    "id\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "1\tTrue\t0.370594\t0.424389\t0.405750\t0.601457\t0.601457\t0.998969\t0.796887\t0.808809\t0.302646\t...\t0.716845\t0.009219\t0.622879\t0.601453\t0.827890\t0.290202\t0.026601\t0.564050\t1\t0.016469\n",
    "2\tTrue\t0.464291\t0.538214\t0.516730\t0.610235\t0.610235\t0.998946\t0.797380\t0.809301\t0.303556\t...\t0.795297\t0.008323\t0.623652\t0.610237\t0.839969\t0.283846\t0.264577\t0.570175\t1\t0.020794\n",
    "3\tTrue\t0.426071\t0.499019\t0.472295\t0.601450\t0.601364\t0.998857\t0.796403\t0.808388\t0.302035\t...\t0.774670\t0.040003\t0.623841\t0.601449\t0.836774\t0.290189\t0.026555\t0.563706\t1\t0.016474\n",
    "4\tTrue\t0.399844\t0.451265\t0.457733\t0.583541\t0.583541\t0.998700\t0.796967\t0.808966\t0.303350\t...\t0.739555\t0.003252\t0.622929\t0.583538\t0.834697\t0.281721\t0.026697\t0.564663\t1\t0.023982\n",
    "5\tTrue\t0.465022\t0.538432\t0.522298\t0.598783\t0.598783\t0.998973\t0.797366\t0.809304\t0.303475\t...\t0.795016\t0.003878\t0.623521\t0.598782\t0.839973\t0.278514\t0.024752\t0.575617\t1\t0.035490\n",
    "5 rows √ó 96 columns\n",
    "\n",
    "‚Äã\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.5\", df)\n",
    "Yes! Keep on rockin'. üé∏That's right.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Explore\n",
    "Task 5.5.6: Is there any missing data in the dataset? Create a Series where the index contains the name of the columns in df and the values are the number of NaNs in each column. Assign the result to nans_by_col. Neither the Series itself nor its index require a name. WQU WorldQuant University Applied Data Science Lab QQQQ\n",
    "\n",
    "df.info()\n",
    "nans_by_col = df.isnull().sum()\n",
    "print(\"nans_by_col shape:\", nans_by_col.shape)\n",
    "nans_by_col.head()\n",
    "nans_by_col shape: (96,)\n",
    "bankrupt    0\n",
    "feat_1      0\n",
    "feat_2      0\n",
    "feat_3      0\n",
    "feat_4      0\n",
    "dtype: int64\n",
    "‚Äã\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.6\", nans_by_col)\n",
    "Python master üòÅ\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.7: Is the data imbalanced? Create a bar chart that shows the normalized value counts for the column df[\"bankrupt\"]. Be sure to label your x-axis \"Bankrupt\", your y-axis \"Frequency\", and use the title \"Class Balance\".\n",
    "\n",
    "# Plot class balance\n",
    "‚Äã\n",
    "df[\"bankrupt\"].value_counts(normalize=True).plot(\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Bankrupt\",\n",
    "    ylabel=\"Frequency\",\n",
    "    title=\"Class Balance\"\n",
    ");\n",
    "# Don't delete the code below üëá\n",
    "plt.savefig(\"images/5-5-7.png\", dpi=150)\n",
    "‚Äã\n",
    "\n",
    "with open(\"images/5-5-7.png\", \"rb\") as file:\n",
    "    wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.7\", file)\n",
    "Python master üòÅ\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Split\n",
    "Task 5.5.8: Create your feature matrix X and target vector y. Your target is \"bankrupt\".\n",
    "\n",
    "target = \"bankrupt\"\n",
    "X = df.drop(columns = \"bankrupt\")\n",
    "y = df[target]\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "X shape: (6137, 95)\n",
    "y shape: (6137,)\n",
    "‚Äã\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.8a\", X)\n",
    "Excellent! Keep going.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "‚Äã\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.8b\", y)\n",
    "Very impressive.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.9: Divide your dataset into training and test sets using a randomized split. Your test set should be 20% of your data. Be sure to set random_state to 42.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    "‚Äã\n",
    ")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "X_train shape: (4909, 95)\n",
    "y_train shape: (4909,)\n",
    "X_test shape: (1228, 95)\n",
    "y_test shape: (1228,)\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.9\", list(X_train.shape))\n",
    "Yup. You got it.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Resample\n",
    "Task 5.5.10: Create a new feature matrix X_train_over and target vector y_train_over by performing random over-sampling on the training data. Be sure to set the random_state to 42.\n",
    "\n",
    "over_sampler = RandomOverSampler(random_state =42)\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n",
    "print(\"X_train_over shape:\", X_train_over.shape)\n",
    "X_train_over.head()\n",
    "X_train_over shape: (9512, 95)\n",
    "feat_1\tfeat_2\tfeat_3\tfeat_4\tfeat_5\tfeat_6\tfeat_7\tfeat_8\tfeat_9\tfeat_10\t...\tfeat_86\tfeat_87\tfeat_88\tfeat_89\tfeat_90\tfeat_91\tfeat_92\tfeat_93\tfeat_94\tfeat_95\n",
    "0\t0.535855\t0.599160\t0.594411\t0.627099\t0.627099\t0.999220\t0.797686\t0.809591\t0.303518\t0.781865\t...\t0.834091\t0.022025\t0.624364\t0.627101\t0.841977\t0.275384\t0.026791\t0.565158\t1\t0.147943\n",
    "1\t0.554136\t0.612734\t0.595000\t0.607388\t0.607388\t0.999120\t0.797614\t0.809483\t0.303600\t0.781754\t...\t0.840293\t0.002407\t0.624548\t0.607385\t0.842645\t0.276532\t0.026791\t0.565158\t1\t0.062544\n",
    "2\t0.549554\t0.603467\t0.599122\t0.620166\t0.620166\t0.999119\t0.797569\t0.809470\t0.303524\t0.781740\t...\t0.840403\t0.000840\t0.624010\t0.620163\t0.842873\t0.277249\t0.026800\t0.565200\t1\t0.047929\n",
    "3\t0.543801\t0.603249\t0.606992\t0.622515\t0.622515\t0.999259\t0.797728\t0.809649\t0.303510\t0.781930\t...\t0.831514\t0.006176\t0.626775\t0.622513\t0.842989\t0.280013\t0.026839\t0.565375\t1\t0.028386\n",
    "4\t0.498659\t0.562364\t0.546978\t0.603670\t0.603670\t0.998904\t0.797584\t0.809459\t0.304000\t0.781713\t...\t0.811988\t0.004256\t0.623674\t0.603669\t0.841105\t0.277628\t0.026897\t0.565618\t1\t0.043080\n",
    "5 rows √ó 95 columns\n",
    "\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.10\", list(X_train_over.shape))\n",
    "You got it. Dance party time! üï∫üíÉüï∫üíÉ\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Build Model\n",
    "Iterate\n",
    "Task 5.5.11: Create a classifier clf that can be trained on (X_train_over, y_train_over). You can use any of the new, ensemble predictors you've learned about in this project.\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.11\", clf)\n",
    "Party time! üéâüéâüéâ\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.12: Perform cross-validation with your classifier using the over-sampled training data, and assign your results to cv_scores. Be sure to set the cv argument to 5.\n",
    "\n",
    "Tip: Use your CV scores to evaluate different classifiers. Choose the one that gives you the best scores.\n",
    "\n",
    "cv_scores = cross_val_score(clf, X_train_over, y_train_over, cv=5, n_jobs=-1)\n",
    "print(cv_scores)\n",
    "[0.99264319 0.99527063 0.99369085 0.99421661 0.9957939 ]\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.12\", list(cv_scores))\n",
    "Yes! Your hard work is paying off.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Ungraded Task: Create a dictionary params with the range of hyperparameters that you want to evaluate for your classifier. If you're not sure which hyperparameters to tune, check the scikit-learn documentation for your predictor for ideas.\n",
    "\n",
    "Tip: If the classifier you built is a predictor only (not a pipeline with multiple steps), you don't need to include the step name in the keys of your params dictionary. For example, if your classifier was only a random forest (not a pipeline containing a random forest), your would access the number of estimators using \"n_estimators\", not \"randomforestclassifier__n_estimators\".\n",
    "\n",
    "params = {\n",
    "   \n",
    "    \"n_estimators\": range (25,100,25),\n",
    "    \"max_depth\": range (10,50,10)\n",
    "}\n",
    "Task 5.5.13: Create a GridSearchCV named model that includes your classifier and hyperparameter grid. Be sure to set cv to 5, n_jobs to -1, and verbose to 1.\n",
    "\n",
    "model = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    n_jobs= -1,\n",
    "    verbose=1\n",
    "‚Äã\n",
    "‚Äã\n",
    ")\n",
    "‚Äã\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.13\", model)\n",
    "Python master üòÅ\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Ungraded Task: Fit your model to the over-sampled training data.\n",
    "\n",
    "model.fit(X_train_over, y_train_over)\n",
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
    "             param_grid={'max_depth': range(10, 50, 10),\n",
    "                         'n_estimators': range(25, 100, 25)},\n",
    "             verbose=1)\n",
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
    "Task 5.5.14: Extract the cross-validation results from your model, and load them into a DataFrame named cv_results. Looking at the results, which set of hyperparameters led to the best performance?\n",
    "\n",
    "cv_results = pd.DataFrame(model.cv_results_)\n",
    "cv_results.head(5)\n",
    "mean_fit_time\tstd_fit_time\tmean_score_time\tstd_score_time\tparam_max_depth\tparam_n_estimators\tparams\tsplit0_test_score\tsplit1_test_score\tsplit2_test_score\tsplit3_test_score\tsplit4_test_score\tmean_test_score\tstd_test_score\trank_test_score\n",
    "0\t1.399944\t0.045620\t0.033540\t0.029621\t10\t25\t{'max_depth': 10, 'n_estimators': 25}\t0.982659\t0.980032\t0.977918\t0.981073\t0.980021\t0.980340\t0.001548\t12\n",
    "1\t2.835837\t0.035168\t0.066094\t0.025867\t10\t50\t{'max_depth': 10, 'n_estimators': 50}\t0.984235\t0.977930\t0.978444\t0.980547\t0.981598\t0.980551\t0.002280\t10\n",
    "2\t4.294487\t0.056046\t0.032925\t0.024109\t10\t75\t{'max_depth': 10, 'n_estimators': 75}\t0.985812\t0.979506\t0.976341\t0.980547\t0.980021\t0.980445\t0.003057\t11\n",
    "3\t1.714188\t0.043114\t0.022544\t0.024158\t20\t25\t{'max_depth': 20, 'n_estimators': 25}\t0.989490\t0.988965\t0.986856\t0.987907\t0.987382\t0.988120\t0.000978\t9\n",
    "4\t3.334628\t0.038123\t0.041301\t0.029540\t20\t50\t{'max_depth': 20, 'n_estimators': 50}\t0.990541\t0.988965\t0.989485\t0.988959\t0.991062\t0.989802\t0.000854\t7\n",
    "‚Äã\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.14\", cv_results)\n",
    "Yes! Great problem solving.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.15: Extract the best hyperparameters from your model and assign them to best_params.\n",
    "\n",
    "best_params = model.best_params_\n",
    "print(best_params)\n",
    "{'max_depth': 30, 'n_estimators': 50}\n",
    "wqet_grader.grade(\n",
    "    \"Project 5 Assessment\", \"Task 5.5.15\", [isinstance(best_params, dict)]\n",
    ")\n",
    "Yes! Great problem solving.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Evaluate\n",
    "Ungraded Task: Test the quality of your model by calculating accuracy scores for the training and test data.\n",
    "\n",
    "acc_train = model.score(X_train, y_train)\n",
    "acc_test = model.score(X_test, y_test)\n",
    "‚Äã\n",
    "print(\"Model Training Accuracy:\", round(acc_train, 4))\n",
    "print(\"Model Test Accuracy:\", round(acc_test, 4))\n",
    "Model Training Accuracy: 1.0\n",
    "Model Test Accuracy: 0.9772\n",
    "Task 5.5.16: Plot a confusion matrix that shows how your model performed on your test set.\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test);\n",
    "# Don't delete the code below üëá\n",
    "plt.savefig(\"images/5-5-16.png\", dpi=150)\n",
    "‚Äã\n",
    "\n",
    "with open(\"images/5-5-16.png\", \"rb\") as file:\n",
    "    wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.16\", file)\n",
    "You got it. Dance party time! üï∫üíÉüï∫üíÉ\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.17: Generate a classification report for your model's performance on the test data and assign it to class_report.\n",
    "\n",
    "class_report = classification_report(y_test, model.predict(X_test))\n",
    "print(class_report)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.98      0.99      0.99      1191\n",
    "        True       0.70      0.43      0.53        37\n",
    "\n",
    "    accuracy                           0.98      1228\n",
    "   macro avg       0.84      0.71      0.76      1228\n",
    "weighted avg       0.97      0.98      0.97      1228\n",
    "\n",
    "wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.17\", class_report)\n",
    "Yes! Great problem solving.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Communicate\n",
    "Task 5.5.18: Create a horizontal bar chart with the 10 most important features for your model. Be sure to label the x-axis \"Gini Importance\", the y-axis \"Feature\", and use the title \"Feature Importance\".\n",
    "\n",
    "features = X_train_over.columns\n",
    "importances = model.best_estimator_.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "feat_imp.tail(10).plot(kind=\"barh\")\n",
    "‚Äã\n",
    "# Don't delete the code below üëá\n",
    "plt.savefig(\"images/5-5-17.png\", dpi=150)\n",
    "‚Äã\n",
    "\n",
    "with open(\"images/5-5-17.png\", \"rb\") as file:\n",
    "    wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.18\", file)\n",
    "Very impressive.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.19: Save your best-performing model to a a file named \"model-5-5.pkl\".\n",
    "\n",
    "# Save model\n",
    "with open(\"model-5-5.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "‚Äã\n",
    "with open(\"model-5-5.pkl\", \"rb\") as f:\n",
    "    wqet_grader.grade(\"Project 5 Assessment\", \"Task 5.5.19\", pickle.load(f))\n",
    "ü•≥\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Task 5.5.20: Open the file my_predictor_assignment.py. Add your wrangle function, and then create a make_predictions function that takes two arguments: data_filepath and model_filepath. Use the cell below to test your module. When you're satisfied with the result, submit it to the grader.\n",
    "\n",
    "# Import your module\n",
    "from my_predictor_assignment import make_predictions\n",
    "‚Äã\n",
    "# Generate predictions\n",
    "y_test_pred = make_predictions(\n",
    "    data_filepath=\"data/taiwan-bankruptcy-data-test-features.json.gz\",\n",
    "    model_filepath=\"model-5-5.pkl\",\n",
    ")\n",
    "‚Äã\n",
    "print(\"predictions shape:\", y_test_pred.shape)\n",
    "y_test_pred.head()\n",
    "predictions shape: (682,)\n",
    "id\n",
    "18    False\n",
    "20    False\n",
    "24    False\n",
    "32    False\n",
    "38    False\n",
    "Name: bankrupt, dtype: bool\n",
    "Tip: If you get an ImportError when you try to import make_predictions from my_predictor_assignment, try restarting your kernel. Go to the Kernel menu and click on Restart Kernel and Clear All Outputs. Then rerun just the cell above. ‚òùÔ∏è\n",
    "wqet_grader.grade(\n",
    "    \"Project 5 Assessment\",\n",
    "    \"Task 5.5.20\",\n",
    "    make_predictions(\n",
    "        data_filepath=\"data/taiwan-bankruptcy-data-test-features.json.gz\",\n",
    "        model_filepath=\"model-5-5.pkl\",\n",
    "    ),\n",
    ")\n",
    "Your model's accuracy score is 0.9589. Excellent work.\n",
    "\n",
    "Score: 1\n",
    "\n",
    "Copyright 2023 WorldQuant University. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
