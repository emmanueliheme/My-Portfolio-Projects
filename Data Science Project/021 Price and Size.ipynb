{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Price with Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import wqet_grader\n",
    "from IPython.display import VimeoVideo\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "wqet_grader.init(\"Project 2 Assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data: Import\n",
    "In the previous project, we cleaned our data files one-by-one. This isn't an issue when you're working with just three files, but imagine if you had several hundred! One way to automate the data importing and cleaning process is by writing a function. This will make sure that all our data undergoes the same process, and that our analysis is easily reproducible — something that's very important in science in general and data science in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filepath):\n",
    "    # Read Csv file into dataframe\n",
    "    df = pd.read_csv(filepath)\n",
    "    #subset for '\"Capital Federal\"'\n",
    "    mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n",
    "    #subset for '\"Apartments\"'\n",
    "    mask_apt = df[\"property_type\"] == \"apartment\"\n",
    "    #subset for < \"400,000\"\n",
    "    mask_price = df[\"price_aprox_usd\"] <400_000\n",
    "    \n",
    "    df = df[mask_ba & mask_apt & mask_price]\n",
    "    #Remove outliers by \"surface_covered_in_m2\"\n",
    "    low, high = df[\"surface_covered_in_m2\"].quantile([0.1,0.9])\n",
    "    mask_area = df[\"surface_covered_in_m2\"].between(low,high)\n",
    "    df = df[mask_area]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle(\"data/buenos-aires-real-estate-1.csv\")\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create histogram\n",
    "plt.hist(df[\"surface_covered_in_m2\"])\n",
    "plt.xlabel(\"Area [sq meters]\")\n",
    "plt.title(\"Distribution of Apartment sizes\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()[\"surface_covered_in_m2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df[\"surface_covered_in_m2\"], y=df[\"price_aprox_usd\"])\n",
    "plt.xlabel(\"Area [sq meters]\")\n",
    "plt.ylabel(\"Price [USD]\")\n",
    "plt.title(\"Buenos Aies Price VS Area\")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split\n",
    "A key part in any model-building project is separating your target (the thing you want to predict) from your features (the information your model will use to make its predictions). Since this is our first model, we'll use just one feature: apartment size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"surface_covered_in_m2\"]\n",
    "X_train = df[features]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"price_aprox_usd\"\n",
    "y_train = df[target]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model: Baseline\n",
    "The first step in building a model is baselining. To do this, ask yourself how you will know if the model you build is performing well?\" One way to think about this is to see how a \"dumb\" model would perform on the same data. Some people also call this a naïve or baseline model, but it's always a model makes only one prediction — in this case, it predicts the same price regardless of an apartment's size. So let's start by figuring out what our baseline model's prediction should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = y_train.mean()\n",
    "y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_baseline = [y_mean] * len(y_train)\n",
    "len(y_pred_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a line to the plot below that shows the relationship between the observations X_train and our dumb model's predictions y_pred_baseline. Be sure that the line color is orange, and that it has the label \"Baseline Model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train.values, y_pred_baseline, label = \"Baseline Model\", color = \"orange\")\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.xlabel(\"Area [sq meters]\")\n",
    "plt.ylabel(\"Price [USD]\")\n",
    "plt.title(\"Buenos Aires: Price vs. Area\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_baseline = mean_absolute_error(y_train, y_pred_baseline)\n",
    "\n",
    "print(\"Mean apt price\", round(y_mean, 2))\n",
    "print(\"Baseline MAE:\", round(mae_baseline, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate\n",
    "The next step in building a model is iterating. This involves building a model, training it, evaluating it, and then repeating the process until you're happy with the model's performance. Even though the model we're building is linear, the iteration process rarely follows a straight line. Be prepared for trying new things, hitting dead-ends, and waiting around while your computer does long computations to train your model. ☕️ Let's get started!\n",
    "\n",
    "The first thing we need to do is create our model — in this case, one that uses linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "The final step is to evaluate our model. In order to do that, we'll start by seeing how well it performs when making predictions for data that it saw during training. So let's have it predict the price for the houses in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_training = model.predict(X_train)\n",
    "y_pred_training[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_training = mean_absolute_error(y_train, y_pred_training)\n",
    "print(\"Training MAE:\", round(mae_training, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: Make sure the X_train you used to train your model has the same column order as X_test. Otherwise, it may hurt your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"data/buenos-aires-test-features.csv\")[features]\n",
    "y_pred_test = pd.Series(model.predict(X_test))\n",
    "y_pred_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: During the iteration phase, you can change and retrain your model as many times as you want. You can also check the model's training performance repeatedly. But once you evaluate its test performance, you can't make any more changes.\n",
    "\n",
    "A test only counts if neither the model nor the data scientist has seen the data before. If you check your test metrics and then make changes to the model, you can introduce biases into the model that compromise its generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communicating Result\n",
    "Once your model is built and tested, it's time to share it with others. If you're presenting to simple linear model to a technical audience, they might appreciate an equation. When we created our baseline model, we represented it as a line. The equation for a line like this is usually written as:\n",
    "\n",
    "<center><img src=\"../images/proj-2.003.png\" alt=\"Equation: y = m*x + b\" style=\"width: 400px;\"/></center>\n",
    "\n",
    "Since data scientists often work with more complicated linear models, they prefer to write the equation as:\n",
    "\n",
    "<center><img src=\"../images/proj-2.004.png\" alt=\"Equation: y = beta 0 + beta 1 * x\" style=\"width: 400px;\"/></center>\n",
    "\n",
    "Regardless of how we write the equation, we need to find the values that our model has determined for the intercept and and coefficient. Fortunately, all trained models in scikit-learn store this information in the model itself. Let's start with the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = round(model.intercept_, 2)\n",
    "print(\"Model Intercept:\", intercept)\n",
    "assert any([isinstance(intercept, int), isinstance(intercept, float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient = round(model.coef_[0], 2)\n",
    "print('Model coefficient for \"surface_covered_in_m2\":', coefficient)\n",
    "assert any([isinstance(coefficient, int), isinstance(coefficient, float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"apt_price= {intercept} + {coefficient} * surface_covered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train, model.predict(X_train), color=\"burlywood\", label=\"Linear Model\")\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.xlabel(\"surface covered [sq meters]\")\n",
    "plt.ylabel(\"price [usd]\")\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
